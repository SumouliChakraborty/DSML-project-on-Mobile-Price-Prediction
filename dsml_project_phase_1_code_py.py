# -*- coding: utf-8 -*-
"""DSML Project Phase-1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sCfEM4iLqbJ8pI0ETfdIBXM_U8J9DySG

# Importing All Necessary Python Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import AdaBoostClassifier
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

"""# Reading Different Data Sets"""

train_data=pd.read_csv("/content/train.csv")

"""# Descriptive  Data Analysis"""

train_data.head()

train_data.info()

train_data.describe()

train_data.shape

#missing values
train_data.isna().any()

"""#Exploratory Data Anylysis"""

price_plot=train_data['price_range'].value_counts().plot(kind='bar')
plt.xlabel('price_range')
plt.ylabel('count')
plt.show()

sns.set(rc={'figure.figsize':(5,5)})
ax=sns.displot(data=train_data["blue"])
plt.show()

sns.pointplot(y="talk_time", x="price_range", data=train_data)

train_data.plot(x='price_range',y='battery_power',kind='scatter')
plt.show()

sns.set(rc={'figure.figsize':(5,5)})
ax=sns.displot(data=train_data["m_dep"])
plt.show()

train_data.plot(x='price_range',y='fc',kind='scatter')
plt.show()

sns.displot(train_data, x='mobile_wt',y='price_range',kind='kde');

sns.displot(train_data, x='ram',y='price_range', color='red',kind='kde');

sns.set(rc={'figure.figsize':(5,5)})
ax=sns.displot(data=train_data["ram"])

plt.show()

labels4g = ["4G-supported",'Not supported']
values4g = train_data['four_g'].value_counts().values
fig1, ax1 = plt.subplots()
ax1.pie(values4g, labels=labels4g, autopct='%1.1f%%',shadow=True,startangle=90)
plt.show()

labels = ["3G-supported",'Not supported']
values=train_data['three_g'].value_counts().values
fig1, ax1 = plt.subplots()
ax1.pie(values, labels=labels, autopct='%1.1f%%',shadow=True,startangle=90)
plt.show()

sns.set(rc={'figure.figsize':(5,5)})
ax=sns.displot(data=train_data["pc"])

plt.show()

"""#Dropping Class Labels"""

X_train = train_data.drop('price_range',axis=1)
y_train = train_data['price_range']

"""#Train-Test Split"""

X_train, X_test, y_train, y_test= train_test_split(X_train, y_train, test_size=0.2, random_state=7)

# Preprocessing the data
from sklearn.preprocessing import MinMaxScaler

# Scaling the Data
scaler = MinMaxScaler(feature_range=(0, 1), copy=True, clip=False)
train_data = scaler.fit_transform(X_train)

def my_confusion_matrix(y_test, y_pred, plt_title):
    cm=confusion_matrix(y_test, y_pred)
    print(classification_report(y_test, y_pred))
    sns.heatmap(cm, annot=True, fmt='g', cbar=False, cmap='BuPu')
    plt.xlabel('Predicted Values')
    plt.ylabel('Actual Values')
    plt.title(plt_title)
    plt.show()
    return cm

"""#Correlation Matrix"""

plt.figure(figsize=(20,20))
sns.heatmap(X_train.corr(),annot=True,cmap=plt.cm.Accent_r)
corr_matrix = X_train.corr()
plt.show()

"""#Building Models

## Random Forest Classification (without hyperparameter tuning)
"""

model = RandomForestClassifier()
model.fit(X_train, y_train)
  
# predict the model
y_pred = model.predict(X_test)
  
# performance evaluation metrics
print('Random Forest Classifier Accuracy Score: ',accuracy_score(y_test,y_pred))
print('f1 Score:', f1_score(y_test, y_pred, average='weighted'))
cm_rfc=my_confusion_matrix(y_test, y_pred, 'Random Forest Confusion Matrix')

"""## Random Forest Classification (with hyperparameter tuning)

"""

param_grid = {
     'n_estimators': [100, 150, 200],
     'max_depth': [5,6,7,8,9,10,11,12],
     'min_samples_leaf': [2, 3, 4],
     'min_samples_split': [6, 8, 10],
     'max_features' : [5,6,7,8,9,10,11,12],
     'criterion' : ['gini', 'entropy', 'log_loss' ]}

grid_search = GridSearchCV(RandomForestClassifier(),param_grid=param_grid, scoring='f1_macro')
grid_search.fit(X_train, y_train)
print(grid_search.best_estimator_)

rfc=RandomForestClassifier(bootstrap= True,
                          criterion='log_loss',
                          max_depth= 9,
                          max_features= 12,
                          min_samples_leaf= 2,
                          min_samples_split= 6,
                          n_estimators= 150,
                          random_state=7)

rfc.fit(X_train, y_train)
y_pred_rfc=rfc.predict(X_test)

print('Random Forest Classifier Accuracy Score: ',accuracy_score(y_test,y_pred_rfc)) #accuracy and confusion matrix of random forest classifier
print('f1 Score:', f1_score(y_test, y_pred_rfc, average='weighted'))
cm_rfc=my_confusion_matrix(y_test, y_pred_rfc, 'Random Forest Confusion Matrix')

"""Points to be noted:

hyperparameter tuning process for a Random Forest Classifier model using GridSearchCV.
GridSearchCV is a function that performs an exhaustive search over a specified hyperparameter grid.
Reason for long time execution:

The Random Forest Classifier is a relatively complex model that requires training multiple decision trees and combining their outputs.
parameter grid contains many hyperparameters and possible values, then the grid search process can take a long time

## Gaussian Naive Bayes (without hyperparameter tuning)
"""

nb = GaussianNB()
nb.fit(X_train, y_train)
nb_pred_wo_tune = nb.predict(X_test)
print('\nAccuracy Score:', accuracy_score(y_test, nb_pred_wo_tune))
print('f1 Score:', f1_score(y_test, nb_pred_wo_tune, average='weighted'))
cm_nb=my_confusion_matrix(y_test, nb_pred_wo_tune, 'Gaussian Naive Bayes Confusion Matrix')

"""## Gaussian Naive Bayes (with hyperparameter tuning)"""

params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}
gs_NB = GridSearchCV(GaussianNB(), param_grid=params_NB, verbose=1, cv=5, scoring='f1_macro') 
gs_NB.fit(X_train, y_train)
gs_NB.best_params_

nb = GaussianNB(var_smoothing= 2.848035868435799e-07)
nb.fit(X_train, y_train)
nb_pred_wo_tune_1 = nb.predict(X_test)
print('Accuracy Score:', accuracy_score(y_test, nb_pred_wo_tune_1))
print('f1 Score:', f1_score(y_test, nb_pred_wo_tune_1, average='weighted'))
cm_nb_ht=my_confusion_matrix(y_test, nb_pred_wo_tune_1, 'Gaussian Naive Bayes Confusion Matrix')

"""# K-Nearest Neighbours"""

error_rate = []

for i in range(1,40):
 
 knn = KNeighborsClassifier(n_neighbors=i)
 knn.fit(X_train,y_train)
 pred_i = knn.predict(X_test)
 error_rate.append(np.mean(pred_i != y_test))

plt.figure(figsize=(10,6))
plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)
plt.title('Error Rate vs. K Value')
plt.xlabel('K')
plt.ylabel('Error Rate')

# grid_params = { 'n_neighbors' : [13,14,15,16,17,24],
#                 'weights' : ['uniform','distance'],
#                 'metric' : ['minkowski','euclidean','manhattan'],
#                 'leaf_size': [5, 7, 9]
#               }

# gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)
# g_res = gs.fit(X_train, y_train)
# g_res.best_params_

knn = KNeighborsClassifier(n_neighbors=24,leaf_size=5, weights='distance', metric='minkowski')

knn.fit(X_train, y_train)
y_pred_knn=knn.predict(X_test)

print('KNN Classifier Accuracy Score: ',accuracy_score(y_test,y_pred_knn))
print('KNN Classifier f1 Score:', f1_score(y_test, y_pred_knn, average='weighted'))
cm_knn=my_confusion_matrix(y_test, y_pred_knn, 'KNN Confusion Matrix')

"""# Support Vector Machine"""

grid_params = {'kernel': ['linear'],
               'C':np.logspace(-8, 2, 11)}
gs = GridSearchCV(SVC(), grid_params, scoring='f1_macro')
g_res = gs.fit(X_train, y_train)
g_res.best_params_

grid_params = {'kernel': ['poly'],
                'degree': [2,3,4,5,6],
                'C': np.logspace(-1, 5, 7)}
gs = GridSearchCV(SVC(), grid_params, scoring='f1_macro')
g_res = gs.fit(X_train, y_train)
g_res.best_params_

grid_params = {'kernel': ['rbf'],
               'gamma': np.logspace(-8, 1, 10),
               'C':np.logspace(-1, 5, 7)}
gs = GridSearchCV(SVC(), grid_params, scoring='f1_macro')
g_res = gs.fit(X_train, y_train)
g_res.best_params_

rbf = SVC(kernel='rbf',C=10000,gamma=1e-08).fit(X_train, y_train)
poly = SVC(kernel='poly', degree=2, C=1000).fit(X_train, y_train)
linear= SVC(kernel='linear', C=0.0001).fit(X_train, y_train)
poly_pred = poly.predict(X_test)
rbf_pred = rbf.predict(X_test)
linear_pred = linear.predict(X_test)

print('SVM (Polynomial) Classifier Accuracy Score: ',accuracy_score(y_test,poly_pred))
print('SVM (Polynomial) Classifier f1 Score:', f1_score(y_test, poly_pred, average='weighted'))
cm_svm=my_confusion_matrix(y_test, poly_pred, 'SVM (Polynomial) Confusion Matrix')

print('SVM (rbf) Classifier Accuracy Score: ',accuracy_score(y_test,rbf_pred))
print('SVM (rbf) Classifier f1 Score:', f1_score(y_test, rbf_pred, average='weighted'))
cm_svm=my_confusion_matrix(y_test, rbf_pred, 'SVM (rbf) Confusion Matrix')

print('SVM (Linear) Classifier Accuracy Score: ',accuracy_score(y_test,linear_pred))
print('SVM (Linear) Classifier f1 Score:', f1_score(y_test, linear_pred, average='weighted'))
cm_svm=my_confusion_matrix(y_test, linear_pred, 'SVM (Linear) Confusion Matrix')

"""# Logistic Regression (without hyparameter tuning)"""

lr=LogisticRegression()                                                                                                                                                                                                                                             
lr.fit(X_train,y_train)
pred2 = lr.predict(X_test)
print('Logistic Regression Classifier Accuracy Score: ',accuracy_score(y_test,pred2))
print('Logistic Regression Classifier f1 Score:', f1_score(y_test, pred2, average='weighted'))
cm_lr=my_confusion_matrix(y_test, pred2, 'Logistic Regression Confusion Matrix')

"""# Logistic Regression (with hyparameter tuning)"""

param_grid = {'penalty':[None,'l2'],
              'C': [0.1,1,2, 5, 8, 10, 100]
              } 


grid = GridSearchCV(LogisticRegression(max_iter = 1000, solver='newton-cg'), param_grid, verbose = False, cv = 5) 

# fitting the model for grid search 
grid.fit(X_train, y_train) 
# print best parameter after tuning 
print('Best hyperparameters:\n', grid.best_params_) 

grid_predictions = grid.predict(X_test) 
  
print('Logistic Regression Classifier Accuracy Score: ',accuracy_score(y_test,grid_predictions))
print('Logistic Regression Classifier f1 Score:', f1_score(y_test, grid_predictions, average='weighted'))
cm_lr=my_confusion_matrix(y_test, grid_predictions, 'Logistic Regression Confusion Matrix')

param_grid = {'penalty':['elasticnet', 'l1', 'l2', None],
              'C': [0.1,1,2, 5, 8, 10, 100]
              } 


grid = GridSearchCV(LogisticRegression(max_iter = 1000, solver='saga'), param_grid, verbose = False, cv = 5) 

# fitting the model for grid search 
grid.fit(X_train, y_train) 
# print best parameter after tuning 
print('Best hyperparameters:\n', grid.best_params_) 

grid_predictions = grid.predict(X_test) 
  
print('Logistic Regression Classifier Accuracy Score: ',accuracy_score(y_test,grid_predictions))
print('Logistic Regression Classifier f1 Score:', f1_score(y_test, grid_predictions, average='weighted'))
cm_lr=my_confusion_matrix(y_test, grid_predictions, 'Logistic Regression Confusion Matrix')

param_grid = {'penalty':['l1','l2'],
              'C': [0.1,1,2, 5, 8, 10, 100]
              } 


grid = GridSearchCV(LogisticRegression(max_iter = 1000, solver='liblinear'), param_grid, verbose = False, cv = 5) 

# fitting the model for grid search 
grid.fit(X_train, y_train) 
# print best parameter after tuning 
print('Best hyperparameters:\n', grid.best_params_) 

grid_predictions = grid.predict(X_test) 
  
print('Logistic Regression Classifier Accuracy Score: ',accuracy_score(y_test,grid_predictions))
print('Logistic Regression Classifier f1 Score:', f1_score(y_test, grid_predictions, average='weighted'))
cm_lr=my_confusion_matrix(y_test, grid_predictions, 'Logistic Regression Confusion Matrix')

# Create adaboost classifer object
dt=DecisionTreeClassifier(max_depth=10)

abc = AdaBoostClassifier(n_estimators=150,learning_rate=1, base_estimator=dt)
# Train Adaboost Classifer
model = abc.fit(X_train, y_train)
#Predict the response for test dataset
y_pred = model.predict(X_test)
# Model Accuracy, how often is the classifier correct?
print("Accuracy:",accuracy_score(y_test, y_pred))

# Create an SVC object
svc = SVC(probability=True, kernel='linear', C=0.0001) #one of our best model

# Create an Adaboost classifier object
abc = AdaBoostClassifier(n_estimators=50, estimator=svc, learning_rate=0.3)

# Train the Adaboost classifier
model = abc.fit(X_train, y_train)

# Predict the response for the test dataset
y_pred = model.predict(X_test)

# Calculate the accuracy of the model
print("Accuracy:",accuracy_score(y_test, y_pred))
print('f1 Score:', f1_score(y_test, y_pred, average='weighted'))
cm_lr=my_confusion_matrix(y_test, y_pred, 'AdaBoost Confusion Matrix')

"""# ANN"""

# Standardize the data
scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)

# Create a sequential ANN model with two hidden layers and a dropout layer for regularization
model = Sequential([
    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.2),
    Dense(16, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])

# Compile the model with binary crossentropy loss and Adam optimizer
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model on the training data for 50 epochs
history = model.fit(X_train_std, y_train, epochs=50, batch_size=32, validation_data=(X_test_std, y_test))

# Evaluate the accuracy on the test data
_, accuracy = model.evaluate(X_test_std, y_test)
print("ANN Accuracy:", accuracy)

def AdaBoost(x_t,x_v,y_t, y_v):
    t_start = time.time() # in seconds
    x_train = x_t
    x_valid = x_v
    y_train = y_t
    y_valid = y_v

    print('\n\t ---------- Training AdaBoost Classifier ---------- \n')
    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=1)
    be1 = SVC(kernel='poly',C=100,probability=True)              
    be2 = LogisticRegression(solver='newton-cg',C=0.001)        
    pipeline11 = Pipeline([('clf11', AdaBoostClassifier(algorithm='SAMME.R'))])
    clf11_parameters = {
        'clf11__base_estimator':[be1,be2,],
        'clf11__n_estimators':[10, 50, 100, 300,], 
        'clf11__learning_rate':[0.0001, 0.001, 0.01, 0.1,],
        'clf11__random_state':[40,]
        }  
    grid_search11 = GridSearchCV(estimator=pipeline11, param_grid=clf11_parameters, n_jobs=-1, cv=cv, scoring='f1_macro')
    grid_search11.fit(x_train,y_train)
    print(f"Best score on Training set :  {grid_search11.best_score_}")
    clf11 = grid_search11.best_estimator_
    print('\n\n The best set of parameters of the pipeline in Training Phase are: ')
    print(clf11) 
    predicted_class_labels11 = clf11.predict(x_valid)  # validation

    print('\n ***  Scores on Validation Data  *** \n ')
    print(classification_report(y_valid, predicted_class_labels11))
    t_ends = time.time() # in seconds
    
    t_net = (t_ends - t_start)/60    # in minutes
    net_time = round(t_net,2)
    print("====================================================================")
    print(f"Process Completed and time taken is : {net_time} minutes")
    print("====================================================================")
    
    return clf11